import os
import fitz
import re
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import hashlib
from openai import OpenAI
from dotenv import load_dotenv

# =============== í™˜ê²½ ì„¤ì • ë° ì „ì—­ ë³€ìˆ˜ ==================
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=openai_api_key)
embedder = SentenceTransformer("jhgan/ko-sroberta-multitask")

FAISS_DIR = "./faiss_db"
os.makedirs(FAISS_DIR, exist_ok=True)

# =============== PDF ë¬¸ì œ/ì •ë‹µ ì¶”ì¶œ í•¨ìˆ˜ ================
def extract_qa_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        text += page.get_text()
    answer_blocks = re.findall(r'ì •\s*ë‹µ[\s\.Â·]*([^\n]+)', text)
    answer_str = ' '.join(answer_blocks)
    answer_map = dict(re.findall(r'(\d+)\.\s*([â‘ -â‘£1-4])', answer_str))
    question_blocks = re.findall(
        r'(\d+)\.\s*([^\n]+?(?:\n[â‘ -â‘£][^\n]+){2,4})', text)
    qa_list = []
    for num, body in question_blocks:
        choices = re.findall(r'[â‘ -â‘£]\s*[^\n]+', body)
        question = re.sub(r'[â‘ -â‘£]\s*[^\n]+', '', body).strip()
        answer = answer_map.get(num, "")
        qa_list.append({
            "number": num,
            "question": question,
            "choices": choices,
            "answer": answer
        })
    return qa_list

# =============== ì„ë² ë”© & FAISS ì¸ë±ìŠ¤ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ===============
def get_faiss_index_paths(pdf_path):
    abs_path = os.path.abspath(pdf_path)
    pdf_hash = hashlib.md5(abs_path.encode()).hexdigest()
    faiss_path = os.path.join(FAISS_DIR, f"{pdf_hash}.faiss")
    embeddings_path = os.path.join(FAISS_DIR, f"{pdf_hash}_embeddings.npy")
    questions_path = os.path.join(FAISS_DIR, f"{pdf_hash}_qa.npy")
    return faiss_path, embeddings_path, questions_path

def save_faiss_index(index, path):
    faiss.write_index(index, path)

def load_faiss_index(path):
    return faiss.read_index(path)

def save_numpy(arr, path):
    np.save(path, arr)

def load_numpy(path):
    return np.load(path, allow_pickle=True)

def create_faiss_index(embeddings):
    d = embeddings.shape[1]
    index = faiss.IndexFlatL2(d)
    index.add(embeddings)
    return index

def get_or_create_index_and_embeddings(pdf_path):
    faiss_path, embeddings_path, qa_path = get_faiss_index_paths(pdf_path)
    if os.path.exists(faiss_path) and os.path.exists(embeddings_path) and os.path.exists(qa_path):
        print("[INFO] ê¸°ì¡´ ì¸ë±ìŠ¤/ì„ë² ë”©/QA ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
        index = load_faiss_index(faiss_path)
        embeddings = load_numpy(embeddings_path)
        qa_list = load_numpy(qa_path).tolist()
    else:
        print("[INFO] ìƒˆë¡œ ì„ë² ë”©/ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        qa_list = extract_qa_from_pdf(pdf_path)
        texts = [
            f"{q['question']} {' '.join(q['choices'])}" if q['choices'] else q['question']
            for q in qa_list
        ]
        embeddings = embedder.encode(texts, convert_to_numpy=True)
        index = create_faiss_index(embeddings)
        save_faiss_index(index, faiss_path)
        save_numpy(embeddings, embeddings_path)
        save_numpy(np.array(qa_list, dtype=object), qa_path)
    return index, embeddings, qa_list

# =============== ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰ ===============
def search_similar(embeddings, qa_list, user_query, top_k=3):
    query_emb = embedder.encode([user_query], convert_to_numpy=True)[0]
    sims = np.dot(embeddings, query_emb) / (np.linalg.norm(embeddings, axis=1) * np.linalg.norm(query_emb))
    idx_sorted = np.argsort(-sims)[:top_k]
    return [qa_list[i] for i in idx_sorted]

# =============== ë¬¸ì œ ìƒì„± (GPT API) ===============
def generate_new_question(user_condition, similar_qas):
    context = ""
    for qa in similar_qas:
        choices = "\n".join(qa["choices"]) if qa["choices"] else ""
        context += f"ë¬¸ì œ: {qa['question']}\në³´ê¸°:\n{choices}\nì •ë‹µ: {qa['answer']}\n\n"
    prompt = f""" ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ì œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ 4ì§€ì„ ë‹¤í˜• ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” AIì…ë‹ˆë‹¤.
{context}
ì´ ë¬¸ì œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ  '{user_condition}'ë¼ëŠ” ì¡°ê±´ ë˜ëŠ” í‚¤ì›Œë“œì— ë¶€í•©í•˜ëŠ” ìƒˆë¡œìš´ 4ì§€ì„ ë‹¤í˜• ë¬¸ì œì™€ ë³´ê¸°ë¥¼ 4ê°œ, ê·¸ë¦¬ê³  ì •ë‹µì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

[ì¶œë ¥ ì˜ˆì‹œ]
ë¬¸ì œ: ...
ë³´ê¸°:
â‘  ...
â‘¡ ...
â‘¢ ...
â‘£ ...
ì •ë‹µ: (ë³´ê¸° ì¤‘ í•˜ë‚˜, ì˜ˆ: â‘¢ ... )
"""
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        temperature=0.7,
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì¸¡ëŸ‰ ê¸°ì‚¬ ì‹œí—˜ ë¬¸ì œë¥¼ ì˜ ë§Œë“œëŠ” AIì•¼."},
            {"role": "user", "content": prompt}
        ]
    )
    return completion.choices[0].message.content.strip()

# =============== ë©”ì¸ ì‹¤í–‰ ===============
if __name__ == "__main__":
    pdf_path = "app/rag/11-3 ëª¨ì˜ê³ ì‚¬(2025).pdf"  # íŒŒì¼ê²½ë¡œ ìˆ˜ì • í•„ìš”
    index, embeddings, qa_list = get_or_create_index_and_embeddings(pdf_path)
    print(f"ë¬¸ì œ ì¶”ì¶œ: {len(qa_list)}ê°œ, ì„ë² ë”© shape: {embeddings.shape}")

    user_condition = input("ì¶œì œí•  ë¬¸ì œ ì¡°ê±´(ì˜ˆ: ì‚¼ê°ì¸¡ëŸ‰, ê±°ë¦¬ì¸¡ëŸ‰, ìˆ˜ì¤€ì¸¡ëŸ‰ ë“±): ").strip()
    similar_qas = search_similar(embeddings, qa_list, user_condition, top_k=3)
    print("\nğŸ” ê²€ìƒ‰ëœ ìœ ì‚¬ ë¬¸ì œ ì˜ˆì‹œ:")
    for qa in similar_qas:
        print(f" - {qa['question']} {' '.join(qa['choices'])} (ì •ë‹µ: {qa['answer']})")
    generated = generate_new_question(user_condition, similar_qas)
    print("\n=== ìƒì„±ëœ ìƒˆ ë¬¸ì œ ===")
    print(generated)
